{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CTScans_for_Covid19_Classification_MobileNet_(2) (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-qyXnKFMIHj"
      },
      "source": [
        "# Mengimpor fungsi library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3KGazgCxy4H"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # The %tensorflow_version magic only works in colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import numpy as np \n",
        "import math, os, sys\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('default')\n",
        "from scipy import ndimage\n",
        "\n",
        "from skimage import measure, morphology\n",
        "from skimage.io import imsave, imread\n",
        "from skimage.filters import threshold_otsu\n",
        "from skimage.transform import resize\n",
        "from skimage import io \n",
        "from skimage.transform import rotate, AffineTransform, warp\n",
        "from skimage import img_as_ubyte\n",
        "from skimage.util import random_noise\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W75JMEc5vnXv"
      },
      "source": [
        "# Mengimpor Dataset Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDTEmYGYSDhh",
        "outputId": "a7ea49c8-e30a-4027-c5db-6ae10db89859"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjr6CepIvxlP"
      },
      "source": [
        "# Membuat Dataframe untuk Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hdNthFMMAmA"
      },
      "source": [
        "mypath= 'gdrive/MyDrive/Dataset/Preprocessed/'\n",
        "\n",
        "file_name = []\n",
        "tag = []\n",
        "full_path = []\n",
        "for path, subdirs, files in os.walk(mypath):\n",
        "    for name in files:\n",
        "        full_path.append(os.path.join(path, name)) \n",
        "        tag.append(path.split('/')[-1])        \n",
        "        file_name.append(name)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIxRFpLwMCFx",
        "outputId": "c2a8e258-fadb-4b47-dec1-9971a98af693"
      },
      "source": [
        "# memasukan variabel yang sudah dikumpulkan pada looping di atas menjadi sebuah dataframe agar rapih\n",
        "df = pd.DataFrame({\"path\":full_path,'file_name':file_name,\"tag\":tag})\n",
        "df.groupby(['tag']).size()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tag\n",
              "Control    4326\n",
              "Type I     4128\n",
              "Type II    3892\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRGOWfVmv4AQ"
      },
      "source": [
        "# Membagi Dataset ke dalam Bentuk Train Data dan Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZu76IuoMHMd"
      },
      "source": [
        "#load library untuk train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#variabel yang digunakan pada pemisahan data ini\n",
        "X= df['path']\n",
        "y= df['tag']\n",
        "\n",
        "# split dataset awal menjadi data train dan test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=300)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt6YT9pgMYKt"
      },
      "source": [
        "# menyatukan kedalam masing-masing dataframe\n",
        "\n",
        "df_tr = pd.DataFrame({'path':X_train\n",
        "              ,'tag':y_train\n",
        "             ,'set':'train'})\n",
        "\n",
        "df_te = pd.DataFrame({'path':X_test\n",
        "              ,'tag':y_test\n",
        "             ,'set':'test'})"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BietD972Mega",
        "outputId": "0259642f-814e-474f-9eb6-5a05f6850268"
      },
      "source": [
        "print('train size', len(df_tr))\n",
        "print('test size', len(df_te))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train size 9876\n",
            "test size 2470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "J_LEwNOWMnxX",
        "outputId": "a49b3428-69cd-4cc3-df41-616e7f222096"
      },
      "source": [
        "# melihat proporsi pada masing masing set apakah sudah ok atau masih ada yang ingin diubah\n",
        "df_all = df_tr.append([df_te]).reset_index(drop=1)\\\n",
        "\n",
        "print('===================================================== \\n')\n",
        "print(df_all.groupby(['set','tag']).size(),'\\n')\n",
        "\n",
        "print('===================================================== \\n')\n",
        "\n",
        "#cek sample datanya\n",
        "df_all.sample(3)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===================================================== \n",
            "\n",
            "set    tag    \n",
            "test   Control     871\n",
            "       Type I      782\n",
            "       Type II     817\n",
            "train  Control    3455\n",
            "       Type I     3346\n",
            "       Type II    3075\n",
            "dtype: int64 \n",
            "\n",
            "===================================================== \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>tag</th>\n",
              "      <th>set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1226</th>\n",
              "      <td>gdrive/MyDrive/Dataset/Preprocessed/Control/IM...</td>\n",
              "      <td>Control</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5455</th>\n",
              "      <td>gdrive/MyDrive/Dataset/Preprocessed/Type II/IM...</td>\n",
              "      <td>Type II</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4810</th>\n",
              "      <td>gdrive/MyDrive/Dataset/Preprocessed/Type I/IMG...</td>\n",
              "      <td>Type I</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   path      tag    set\n",
              "1226  gdrive/MyDrive/Dataset/Preprocessed/Control/IM...  Control  train\n",
              "5455  gdrive/MyDrive/Dataset/Preprocessed/Type II/IM...  Type II  train\n",
              "4810  gdrive/MyDrive/Dataset/Preprocessed/Type I/IMG...   Type I  train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZji87k8M6Yu"
      },
      "source": [
        "import shutil\n",
        "from tqdm.notebook import tqdm as tq\n",
        "import shutil\n",
        "import os, sys"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGuQmOQVwIDJ"
      },
      "source": [
        "# Membuat Folder Baru untuk Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgWROw_DM_J4"
      },
      "source": [
        "## create folders\n",
        "os.makedirs('Dataset/')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBJ2NljFwRx1"
      },
      "source": [
        "# Menyalin Dataset ke dalam Folder Dataset Baru"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "7CXZFR-hNAS_",
        "outputId": "2e576423-17e4-494e-8611-989b89abfb16"
      },
      "source": [
        "datasource_path = \"gdrive/MyDrive/Dataset/Preprocessed/\"\n",
        "dataset_path = \"Dataset/\"\n",
        "\n",
        "for index, row in tq(df_all.iterrows()):\n",
        "    \n",
        "    #detect filepath\n",
        "    file_path = row['path']\n",
        "    if os.path.exists(file_path) == False:\n",
        "            file_path = os.path.join(datasource_path,row['tag'],row['image'].split('.')[0])            \n",
        "    \n",
        "    #make folder destination dirs\n",
        "    if os.path.exists(os.path.join(dataset_path,row['set'],row['tag'])) == False:\n",
        "        os.makedirs(os.path.join(dataset_path,row['set'],row['tag']))\n",
        "    \n",
        "    #define file dest\n",
        "    destination_file_name = file_path.split('/')[-1]\n",
        "    file_dest = os.path.join(dataset_path,row['set'],row['tag'],destination_file_name)\n",
        "    \n",
        "    #copy file from source to dest\n",
        "    if os.path.exists(file_dest) == False:\n",
        "        shutil.copy2(file_path,file_dest)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3f39c87e08af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Dataset/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#detect filepath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tq' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZS3nylQwauE"
      },
      "source": [
        "# Pre-processing dan Augmentasi Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3dTBuR3NPJ-"
      },
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255, \n",
        "    validation_split = 0.4,\n",
        "    rotation_range = 30,\n",
        "    horizontal_flip = True,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.1,    \n",
        "    vertical_flip = True,\n",
        "    fill_mode = \"nearest\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPKzgPZrMYKT"
      },
      "source": [
        "# Mengimpor Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MC8ipRTyNkb"
      },
      "source": [
        "#Memuat semua gambar ke memori untuk pertama kali\n",
        "\n",
        "#Memuat dataset pelatihan\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 126\n",
        "base_dir = os.path.join('Dataset/train/')\n",
        "\n",
        "\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='training',\n",
        "    class_mode= 'categorical')\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE, \n",
        "    subset='validation',\n",
        "    class_mode= 'categorical')\n",
        "\n",
        "#Memuat dataset pengujian\n",
        "X_test = []\n",
        "y_test = []\n",
        "labels = ['Control',\n",
        "          'Type I',\n",
        "          'Type II',]\n",
        "\n",
        "for i,label in enumerate(labels):\n",
        "    folder = os.path.join(\"Dataset/test\",label)\n",
        "    files = sorted(os.listdir(folder))\n",
        "    files = [x for x in files if x.endswith(\".jpg\")]\n",
        "    for k,file in enumerate(files):\n",
        "        image_path = os.path.join(folder, file)\n",
        "        \n",
        "        image = imread(image_path)/255.\n",
        "        image = resize(image,(224,224))\n",
        "        X_test.append(image)\n",
        "        category = os.path.split(folder)[-1]\n",
        "        y_test.append(i)\n",
        "\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "#Menampilkan bentuk dari masing-masing dataset\n",
        "for image_batch, label_batch in train_generator:\n",
        "  break\n",
        "print(\"Bentuk array dari dataset train (pelatihan) adalah:\", image_batch.shape,label_batch.shape)\n",
        "for image_batch, label_batch in val_generator:\n",
        "  break\n",
        "print(\"Bentuk array dari dataset validation (validasi) adalah:\", image_batch.shape,label_batch.shape)\n",
        "print(\"Bentuk array dari dataset test (pengujian) adalah:\", X_test.shape,y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJkyzMqvMjyp"
      },
      "source": [
        "# Menyimpan label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuiWFi8gyryf"
      },
      "source": [
        "print (train_generator.class_indices)\n",
        "\n",
        "labels_txt = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write(labels_txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auIaOCxgyguD"
      },
      "source": [
        "!cat labels.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdKpWZTBMwSb"
      },
      "source": [
        "# Membuat model CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrQKX9HVzbdY"
      },
      "source": [
        "IMG_SHAPE = (224, 224, 3)\n",
        "# Membuat model dasar (base model) dari pre-trained model MobileNet\n",
        "base_model = tf.keras.applications.MobileNet(input_shape=IMG_SHAPE,\n",
        "                                              include_top=False, \n",
        "                                              weights='imagenet')\n",
        "\n",
        "base_model.trainable = False\n",
        "base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-JJL-gNzo4F"
      },
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8kb4gw2zko6"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    base_model,    \n",
        "    tf.keras.layers.Conv2D(512, 3, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "]\n",
        ")\n",
        "\n",
        "model.compile(\"adam\",loss=\"categorical_crossentropy\",metrics=[\"acc\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5RxA8NlwkPY"
      },
      "source": [
        "# Melatih Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6cYQQ_8z294"
      },
      "source": [
        "history = model.fit_generator(train_generator, \n",
        "                    epochs=20, \n",
        "                    validation_data=val_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iN51d-xNJhB"
      },
      "source": [
        "# Menampilkan Hasil Pelatihan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK0JIgi2LOVi"
      },
      "source": [
        "plt.plot(history.history[\"acc\"],label=\"Akurasi Pelatihan\")\n",
        "plt.plot(history.history[\"val_acc\"],label=\"Validasi Akurasi\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history[\"loss\"],label=\"Kesalahan Pelatihan\")\n",
        "plt.plot(history.history[\"val_loss\"],label=\"Validasi Kesalahan\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uVvPRuNyo2z"
      },
      "source": [
        "# Memuat Dataset Pengujian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux55Q_SiysJO"
      },
      "source": [
        "y_test2 = to_categorical(y_test)\n",
        "X_test3, y_test3 = (X_test, y_test2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4xOILgHyz8U"
      },
      "source": [
        "# Mengevaluasi Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w-YNZGHy3PZ"
      },
      "source": [
        "#Menampilkan matriks yang benar dan matriks hasil prediksi\n",
        "\n",
        "#Label yang benar\n",
        "y_true = np.argmax(y_test2,axis=1)\n",
        "\n",
        "#Label prediksi\n",
        "Y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "print(y_true)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nWovNwNNPSS"
      },
      "source": [
        "# Menggunakan Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63DCEjBgLYR0"
      },
      "source": [
        "print('Number of trainable variables = {}'.format(len(model.trainable_variables)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnycI6tdzQZ7"
      },
      "source": [
        "# Memprediksi Citra Secara Individu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsFCpQoBLr5y"
      },
      "source": [
        "n = 44 #Jangan melampaui (nilai dari gambar test - 1)\n",
        "\n",
        "plt.imshow(X_test[n])\n",
        "plt.show()\n",
        "\n",
        "true_label = np.argmax(y_test2,axis=1)[n]\n",
        "print(\"Label yang benar adalah:\",true_label,\":\",labels[true_label])\n",
        "prediction = model.predict(X_test[n][np.newaxis,...])[0]\n",
        "print(\"Nilai yang diprediksi adalah:\",prediction)\n",
        "predicted_label = np.argmax(prediction)\n",
        "print(\"Label yang diprediksi adalah:\",predicted_label,\":\",labels[predicted_label])\n",
        "\n",
        "if true_label == predicted_label:\n",
        "    print(\"Prediksi benar\")\n",
        "else:\n",
        "    print(\"Prediksi salah\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lf_8Nkxze14"
      },
      "source": [
        "# Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xp-a3UWzhdB"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, classes,\n",
        "                          normalize=False,\n",
        "                          title=None,\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if not title:\n",
        "        if normalize:\n",
        "            title = 'Normalized confusion matrix'\n",
        "        else:\n",
        "            title = 'Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # Only use the labels that appear in the data\n",
        "    #classes = classes[unique_labels(y_true, y_pred)]\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(5,5))\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    #ax.figure.colorbar(im, ax=ax)\n",
        "    # We want to show all ticks...\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "           yticks=np.arange(cm.shape[0]),\n",
        "           # ... and label them with the respective list entries\n",
        "           xticklabels=classes, yticklabels=classes,\n",
        "           title=title,\n",
        "           ylabel='Label Benar',\n",
        "           xlabel='Label Prediksi')\n",
        "\n",
        "    # Rotate the tick labels and set their alignment.\n",
        "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "             rotation_mode=\"anchor\")\n",
        "\n",
        "    # Loop over data dimensions and create text annotations.\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, format(cm[i, j], fmt),\n",
        "                    ha=\"center\", va=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "    return ax\n",
        "\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "plot_confusion_matrix(y_true, y_pred, classes=labels, normalize=True,\n",
        "                      title='Normalized confusion matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eeYpuBBe-TzK"
      },
      "source": [
        "# Menyimpan dan mengkonversi Model ke \".tflite\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pKV3k8d-SJ-"
      },
      "source": [
        "saved_model_dir = 'save/model'\n",
        "tf.saved_model.save(model, saved_model_dir)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('CTScans_for_Covid19_Classification_MobileNet.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelpredict.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_PEROIT9bgD"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0jItWa3TbgS"
      },
      "source": [
        "import os\n",
        "import cv2 \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from keras.models import load_model\n",
        "import skimage\n",
        "from skimage import measure\n",
        "from collections import Counter"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEVpiTMC9hF8"
      },
      "source": [
        "# Import Dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGK6EzF0TfQG",
        "outputId": "7a1df422-56be-42ef-b066-11142c086919"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps-xjM4-Uodr"
      },
      "source": [
        "target_dir='/content/gdrive/Shareddrives/Soedirman-Machine-Learning/CT SCAN COVID-19/Demo Patient'\n",
        "output_dir='/content/gdrive/Shareddrives/Soedirman-Machine-Learning/CT SCAN COVID-19/Demo Patient Lung'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfdHklnC9nH4"
      },
      "source": [
        "\n",
        "\n",
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG6ibbaaU2Ty"
      },
      "source": [
        "model_CT=load_model(\"/content/gdrive/Shareddrives/Soedirman-Machine-Learning/CT SCAN COVID-19/Model/model_CT.h5\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1G-AL99-OiP"
      },
      "source": [
        "# Pre-processing Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCN2NSuAU_n4"
      },
      "source": [
        "def split_target_dir(target_dir, output_dir):\n",
        "    target_list = [target_dir + os.sep + file for file in os.listdir(target_dir)]\n",
        "    for target in target_list:\n",
        "        img_split = split_lung_parenchyma(target, 10999, -96)\n",
        "        dst = target.replace(target_dir, output_dir)\n",
        "        dst_dir = os.path.split(dst)[0]\n",
        "        if not os.path.exists(dst_dir):\n",
        "            os.makedirs(dst_dir)\n",
        "        cv2.imencode('.jpg', img_split)[1].tofile(dst)\n",
        "    print(f'Target list done with {len(target_list)} items')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2iaoOjgVNKy"
      },
      "source": [
        "def split_lung_parenchyma(target,size,thr):\n",
        "    img=cv2.imdecode(np.fromfile(target,dtype=np.uint8),cv2.IMREAD_GRAYSCALE)\n",
        "    try:\n",
        "        img_thr= cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV,size,thr).astype(np.uint8)\n",
        "    except:\n",
        "        img_thr= cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV,999,thr).astype(np.uint8)\n",
        "    img_thr=255-img_thr\n",
        "    img_test=measure.label(img_thr, connectivity = 1)\n",
        "    props = measure.regionprops(img_test)\n",
        "    img_test.max()\n",
        "    areas=[prop.area for prop in props]\n",
        "    ind_max_area=np.argmax(areas)+1\n",
        "    del_array = np.zeros(img_test.max()+1)\n",
        "    del_array[ind_max_area]=1\n",
        "    del_mask=del_array[img_test]\n",
        "    img_new = img_thr*del_mask\n",
        "    mask_fill=fill_water(img_new)\n",
        "    img_new[mask_fill==1]=255\n",
        "    img_new = 255-img_new\n",
        "    _, labels, stats, centroids = cv2.connectedComponentsWithStats(img_new.astype( np.uint8 ))\n",
        "    labels = np.array(labels, dtype=np.float)\n",
        "    maxnum = Counter(labels.flatten()).most_common(3)\n",
        "    maxnum = sorted([x[0] for x in maxnum])\n",
        "    background = np.zeros_like(labels)\n",
        "    if len(maxnum) == 1:\n",
        "        pass\n",
        "    elif len(maxnum) == 2:\n",
        "        background[labels == maxnum[1]] = 1\n",
        "    else:\n",
        "        background[labels == maxnum[1]] = 1\n",
        "        background[labels == maxnum[2]] = 1\n",
        "    img_new[background == 0] = 0\n",
        "    img_new=cv2.dilate(img_new, np.ones((5,5),np.uint8) , iterations=3)\n",
        "    img_new = cv2.erode(img_new, np.ones((5, 5), np.uint8), iterations=2)\n",
        "    img_new = cv2.morphologyEx(img_new, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_RECT, (10, 10)),iterations=2)\n",
        "    img_new = cv2.medianBlur(img_new.astype(np.uint8), 21)\n",
        "    img_out=img*img_new.astype(bool)\n",
        "    return img_out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ye3QmtGVpUf"
      },
      "source": [
        "def fill_water(img):\n",
        "    copyimg = img.copy()\n",
        "    copyimg.astype(np.float32)\n",
        "\n",
        "    height, width = img.shape\n",
        "    img_exp = np.zeros((height + 20, width + 20))\n",
        "    height_exp, width_exp = img_exp.shape\n",
        "    img_exp[10:-10, 10:-10] = copyimg\n",
        "\n",
        "    mask1 = np.zeros([height + 22, width + 22], np.uint8)\n",
        "    mask2 = mask1.copy()\n",
        "    mask3 = mask1.copy()\n",
        "    mask4 = mask1.copy()\n",
        "\n",
        "    cv2.floodFill(np.float32(img_exp), mask1, (0, 0), 1)\n",
        "    cv2.floodFill(np.float32(img_exp), mask2, (height_exp - 1, width_exp - 1), 1)\n",
        "    cv2.floodFill(np.float32(img_exp), mask3, (height_exp - 1, 0), 1)\n",
        "    cv2.floodFill(np.float32(img_exp), mask4, (0, width_exp - 1), 1)\n",
        "\n",
        "    mask = mask1 | mask2 | mask3 | mask4\n",
        "\n",
        "    output = mask[1:-1, 1:-1][10:-10, 10:-10]\n",
        "    return output"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvvC83OvVvE4"
      },
      "source": [
        "def read_ct_img_bydir(target_dir):\n",
        "    img=cv2.imdecode(np.fromfile(target_dir,dtype=np.uint8),cv2.IMREAD_GRAYSCALE)\n",
        "    img=cv2.resize(img,(224,224))\n",
        "    return img"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0mWmx7nYesA"
      },
      "source": [
        "img_list=[target_dir+os.sep+file for file in os.listdir(target_dir)]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QewWE9Rm4d34"
      },
      "source": [
        "def top_time_series(df,top=10,time_seq=True,del_deficiency=True,invalid_cutoff=0.5):\n",
        "    df=df[df['NiCT']<=invalid_cutoff]\n",
        "    df.sort_values('pCT',ascending=0,inplace=True)\n",
        "    if time_seq:\n",
        "        df=df.head(top).sort_index()\n",
        "    else:\n",
        "        df=df.head(top)\n",
        "    if len(df)<top:\n",
        "        print('Patient with not enough CTs')\n",
        "    return df"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kJgHgi04meN"
      },
      "source": [
        "def is_number(s):\n",
        "    try:\n",
        "        float(s)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        pass\n",
        "    try:\n",
        "        import unicodedata\n",
        "        unicodedata.numeric(s)\n",
        "        return True\n",
        "    except (TypeError, ValueError):\n",
        "        pass\n",
        "    return False"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3k9KN0V4txV"
      },
      "source": [
        "def X_fromdf(df_top):\n",
        "    X=np.array([read_ct_img_bydir(file) for file in df_top['File'].tolist()])\n",
        "    X=X[:,:,:,np.newaxis].transpose(3,1,2,0)[np.newaxis,:,:,:]\n",
        "    return np.concatenate(X)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DacyveuK-geI"
      },
      "source": [
        "# Copy Dataset to New Directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTsNSIRg5DYE",
        "outputId": "b1581265-d835-47f9-f1c9-e284674c85fe"
      },
      "source": [
        "split_target_dir(target_dir,output_dir)\n",
        "img_list=[output_dir+os.sep+file for file in os.listdir(output_dir)]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target list done with 28 items\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIkCMKth-neH"
      },
      "source": [
        "# Use Model for Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpzXh1Ch5IZ9",
        "outputId": "3a7da0ce-b8de-4ada-95c5-78d8edda91da"
      },
      "source": [
        "X_CT_Valid=np.array([read_ct_img_bydir(file) for file in img_list])\n",
        "X_CT_Valid = np.repeat(np.expand_dims(X_CT_Valid, axis=3), 3, axis=3)\n",
        "y_CT_Valid=model_CT.predict_proba(X_CT_Valid)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
            "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNxIepU6-viJ"
      },
      "source": [
        "# Save Predict Value to .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAWbzpM888_U"
      },
      "source": [
        "df=pd.DataFrame({'File':img_list,'NiCT':y_CT_Valid[:,0],'pCT':y_CT_Valid[:,1],'nCT':y_CT_Valid[:,2]})\n",
        "df.to_csv('Demo_img_score.txt',sep='\\t',index=None)"
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}